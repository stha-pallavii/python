{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c885b6",
   "metadata": {},
   "source": [
    "\n",
    "# A. Transforming DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4389410",
   "metadata": {},
   "source": [
    "### 1. Introducing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4a3b0",
   "metadata": {},
   "source": [
    "#### 1.1 Introducing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1f53ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'homelessness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Exploring a dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Print the head of the homelessness data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhomelessness\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print information about homelessness\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(homelessness\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'homelessness' is not defined"
     ]
    }
   ],
   "source": [
    "## Exploring a dataframe\n",
    "\n",
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())\n",
    "\n",
    "# Print information about homelessness\n",
    "print(homelessness.info())\n",
    "\n",
    "# Print the shape of homelessness\n",
    "print(homelessness.shape)\n",
    "\n",
    "# Print a description of homelessness\n",
    "print(homelessness.describe())\n",
    "\n",
    "\n",
    "## Parts of a dataframe\n",
    "\n",
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Print the values of homelessness\n",
    "print(homelessness.values)\n",
    "\n",
    "# Print the column index of homelessness\n",
    "print(homelessness.columns)\n",
    "\n",
    "# Print the row index of homelessness\n",
    "print(homelessness.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70867ca9",
   "metadata": {},
   "source": [
    "#### 1.2.1 Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5d5a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'homelessness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Sort homelessness by individuals\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m homelessness_ind \u001b[38;5;241m=\u001b[39m \u001b[43mhomelessness\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividuals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the top few rows\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(homelessness_ind\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'homelessness' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by individuals\n",
    "homelessness_ind = homelessness.sort_values(\"individuals\")\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_ind.head())\n",
    "\n",
    "# Sort homelessness by descending family members\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\", ascending=False)\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_fam.head())\n",
    "\n",
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values([\"region\", \"family_members\"], ascending=[True, False])\n",
    "\n",
    "# Print the top few rows\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264e487",
   "metadata": {},
   "source": [
    "#### 1.2.2 Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0cd063",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'homelessness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Subsetting columns \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## Susetting single column\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Select the individuals column\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m individuals \u001b[38;5;241m=\u001b[39m \u001b[43mhomelessness\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividuals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print the head of the result\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(individuals\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'homelessness' is not defined"
     ]
    }
   ],
   "source": [
    "## Subsetting columns \n",
    "\n",
    "## Susetting single column\n",
    "# Select the individuals column\n",
    "individuals = homelessness[\"individuals\"]\n",
    "\n",
    "# Print the head of the result\n",
    "print(individuals.head())\n",
    "\n",
    "\n",
    "## Susetting multiple columns\n",
    "# Select the state and family_members columns\n",
    "state_fam = homelessness[[\"state\", \"family_members\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(state_fam.head())\n",
    "\n",
    "\n",
    "# Select only the individuals and state columns, in that order\n",
    "ind_state = homelessness[[\"individuals\", \"state\"]]\n",
    "\n",
    "# Print the head of the result\n",
    "print(ind_state.head())\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "## Subsetting rows\n",
    "\n",
    "## Subsetting rows by creating logical operators\n",
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness[\"individuals\"]>10000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)\n",
    "\n",
    "\n",
    "## Subsetting rows based on text data\n",
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homelessness[homelessness[\"region\"] == \"Mountain\"]\n",
    "\n",
    "# See the result\n",
    "print(mountain_reg)\n",
    "\n",
    "\n",
    "## Subsetting rows based on multiple conditions\n",
    "# Filter for rows where family_members is less than 1000 and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness[\"family_members\"]<1000) & (homelessness[\"region\"] == \"Pacific\")]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)\n",
    "\n",
    "\n",
    "## Subsetting rows using .isin() \n",
    "# Subset for rows in South Atlantic or Mid-Atlantic regions\n",
    "south_mid_atlantic = homelessness[ homelessness[\"region\"].isin([\"South Atlantic\",\"Mid-Atlantic\"])]\n",
    "\n",
    "# See the result\n",
    "print(south_mid_atlantic)\n",
    "\n",
    "\n",
    "## Subsetting rows using .isin() list\n",
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb526b8",
   "metadata": {},
   "source": [
    "#### 1.3 Adding new Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness[\"total\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"]\n",
    "\n",
    "# Add p_individuals col as proportion of total that are individuals\n",
    "homelessness[\"p_individuals\"] = homelessness[\"individuals\"]/homelessness[\"total\"]\n",
    "\n",
    "# See the result\n",
    "print(homelessness)\n",
    "\n",
    "\n",
    "\n",
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"]>20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1a24a",
   "metadata": {},
   "source": [
    "# B. Aggregating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d09a4",
   "metadata": {},
   "source": [
    "### 2.1 Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f94de",
   "metadata": {},
   "source": [
    "2.1.1 Mean and Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06152ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91299a1",
   "metadata": {},
   "source": [
    "2.1.2 Summarizing Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f999151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales[\"date\"].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cee65",
   "metadata": {},
   "source": [
    "2.1.3 Efficient Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales[\"temperature_c\"].agg(iqr))\n",
    "\n",
    "\n",
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))\n",
    "\n",
    "\n",
    "\n",
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438e80e",
   "metadata": {},
   "source": [
    "2.1.4 Cumulative Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4304ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55ec98",
   "metadata": {},
   "source": [
    "### 2.2 Counting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61c4b3",
   "metadata": {},
   "source": [
    "2.2.1 Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf30220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset = [\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset = [\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = (sales[sales[\"is_holiday\"]==True]).drop_duplicates(subset = \"date\")\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaa9e1f",
   "metadata": {},
   "source": [
    "2.2.2 Counting Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f24ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad465b",
   "metadata": {},
   "source": [
    "### 2.3 Grouped Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f34493",
   "metadata": {},
   "source": [
    "#### 2.3.1 What percentage of sales occured at each store types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e553df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"]==\"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"]==\"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493f874",
   "metadata": {},
   "source": [
    "#### 2.3.2 Calculations with .groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "print(sales_propn_by_type)\n",
    "\n",
    "\n",
    "# From previous step\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159c965",
   "metadata": {},
   "source": [
    "#### 2.3.3 Multiple grouped summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a00f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy with the alias np\n",
    "import numpy as np\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([min, max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([min, max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86c70b",
   "metadata": {},
   "source": [
    "### 2.4 Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1f9c6",
   "metadata": {},
   "source": [
    "#### 2.4.1 Pivoting on one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values=\"weekly_sales\", index = \"type\")\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)\n",
    "\n",
    "\n",
    "\n",
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(values = \"weekly_sales\", index = \"type\", aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)\n",
    "\n",
    "\n",
    "\n",
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(values = \"weekly_sales\", index = \"type\", columns = \"is_holiday\")\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c78ad",
   "metadata": {},
   "source": [
    "#### 2.4.2 Fill missing values and Sum values with pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns = \"type\", fill_value = 0))\n",
    "\n",
    "\n",
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values = \"weekly_sales\", index = \"department\", columns = \"type\", fill_value = 0, margins = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1e209",
   "metadata": {},
   "source": [
    "# C. Slicing and Indexing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182eb94",
   "metadata": {},
   "source": [
    "### 3.1 Explicit Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71305c",
   "metadata": {},
   "source": [
    "#### 3.1.1 Setting and removing indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65442561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at temperatures\n",
    "print(temperatures.head())\n",
    "\n",
    "# Set the index of temperatures to city\n",
    "temperatures_ind = temperatures.set_index(\"city\")\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n",
    "\n",
    "# Reset the temperatures_ind index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the temperatures_ind index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6aa78",
   "metadata": {},
   "source": [
    "#### 3.1.2 Subsetting with .loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "temp_sub = temperatures[temperatures[\"city\"].isin([\"Moscow\", \"Saint Petersburg\"])]\n",
    "print(temp_sub)\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[[\"Moscow\", \"Saint Petersburg\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f4161",
   "metadata": {},
   "source": [
    "#### 3.1.3 Setting multi-level indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16683e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf2f19",
   "metadata": {},
   "source": [
    "#### 3.1.4 Sorting by index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level=\"city\"))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level = [\"country\", \"city\"], ascending = [True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb162f3e",
   "metadata": {},
   "source": [
    "### 3.2 Slicing and subsetting with .loc and .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a46aa",
   "metadata": {},
   "source": [
    "#### 3.2.1 Slicing index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc[\"Pakistan\":\"Russia\"])\n",
    "\n",
    "# Try to subset rows from Lahore to Moscow\n",
    "print(temperatures_srt.loc[\"Lahore\": \"Moscow\"])   #returns nonsense value\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[(\"Pakistan\", \"Lahore\"): (\"Russia\", \"Moscow\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1db29",
   "metadata": {},
   "source": [
    "#### 3.2.2 Slicing in both directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d32f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"): (\"Iraq\", \"Baghdad\")])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"): (\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4dec32",
   "metadata": {},
   "source": [
    "#### 3.2.3 Slicing time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool =temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\n",
    "print(temperatures_bool)\n",
    "\n",
    "# Set date as the index and sort the index\n",
    "temperatures_ind = temperatures.set_index(\"date\").sort_index()\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n",
    "print(temperatures_ind.loc[\"2010\":\"2011\"])\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc[\"2010-08\":\"2011-02\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb508f6a",
   "metadata": {},
   "source": [
    "#### 3.2.4 Subsetting by row/column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[:22, :1])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[:6])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:, 2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:6, 2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d54a9e",
   "metadata": {},
   "source": [
    "### 3.3 Working with Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1b3da",
   "metadata": {},
   "source": [
    "#### 3.3.1 Pivot temperature by city and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc2f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab2dbe3",
   "metadata": {},
   "source": [
    "#### 3.3.2 Subsetting pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "293c02b5",
   "metadata": {},
   "source": [
    "#### 3.3.3 Calculating on a pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc13a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "704ec294",
   "metadata": {},
   "source": [
    "# D. Creating and Visualizing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029b346",
   "metadata": {},
   "source": [
    "### 4.1 Visualizing your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4205591",
   "metadata": {},
   "source": [
    "#### 4.1.1 Which avocado size is most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1631281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273f574e",
   "metadata": {},
   "source": [
    "#### 4.1.2 Changes in sales over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e6ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd79ba60",
   "metadata": {},
   "source": [
    "#### 4.1.3 Avocado supply and demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e71c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66f24558",
   "metadata": {},
   "source": [
    "#### 4.1.4 Price of conventional vs organic avocados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ad912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f283bf",
   "metadata": {},
   "source": [
    "### 4.2 Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638406e1",
   "metadata": {},
   "source": [
    "#### 4.2.1 Finding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d771b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6032362a",
   "metadata": {},
   "source": [
    "#### 4.2.2 Removing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341b699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b65558",
   "metadata": {},
   "source": [
    "#### 4.2.3 Replacing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b30db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21fe24e",
   "metadata": {},
   "source": [
    "### 4.3 Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d50e1",
   "metadata": {},
   "source": [
    "#### 4.3.1 List of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cded22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "114c1346",
   "metadata": {},
   "source": [
    "#### 4.3.2 Dictionary of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1429519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22988044",
   "metadata": {},
   "source": [
    "### 4.4 Reading and writing CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efdeaa",
   "metadata": {},
   "source": [
    "#### 4.4.1 CSV to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5ea21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b1419b9",
   "metadata": {},
   "source": [
    "#### 4.4.2 DataFrame to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74924d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d47c768",
   "metadata": {},
   "source": [
    "### 4.5 Wrap up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
